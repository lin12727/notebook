# Ingress基础配置

## 拉取与部署Ingress

~~~
[root@k8s-node k8s]# kubectl apply -f ingress-controller.yaml 
~~~

确保部署成功：

~~~
[root@k8s-node k8s]# kubectl get pods --all-namespaces
NAMESPACE       NAME                               READY   STATUS    RESTARTS   AGE
ingress-nginx   nginx-ingress-controller-rp8bv     1/1     Running   0          119s
ingress-nginx   nginx-ingress-controller-w248k     1/1     Running   0          119s
~~~

## 创建Ingress规则

实现域名访问效果

~~~
apiVersion: v1
kind: Service
metadata:
  labels:
    app: tomcat6
  name: tomcat6
spec:
  ports:
  - port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    app: tomcat6
  type: NodePort
~~~



这里在之前的tomcat的暴露端口就已经设置：将80端口暴露给8080端口了，所以在Ingress只需要对应的80端口就可以了

~~~
[root@k8s-node k8s]# vi ingress-tomcat6.yaml
[root@k8s-node k8s]# cat ingress-tomcat6.yaml 
apiVersion: extensions/v1beta1 
kind: Ingress
metadata:
  name: web 
spec:
  rules:
  - host: tomcat6.atguigu.com
    http:
      paths:
        - backend:
           serviceName: tomcat6 
           servicePort: 80
[root@k8s-node k8s]# kubectl apply -f ingress-tomcat6.yaml 
Warning: extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 Ingress
ingress.extensions/web created
~~~

模拟宕机，也是可以成功的，现在可以实现了域名访问效果

~~~
[root@k8s-node k8s]# kubectl get all -o wide
NAME                           READY   STATUS        RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES
pod/tomcat6-56fcc999cb-jhf5m   1/1     Terminating   0          35m   10.244.1.3   k8s-node1   <none>           <none>
pod/tomcat6-56fcc999cb-n4v2m   1/1     Running       0          35m   10.244.2.4   k8s-node2   <none>           <none>
pod/tomcat6-56fcc999cb-v9jqc   1/1     Running       0          35m   10.244.2.5   k8s-node2   <none>           <none>
pod/tomcat6-56fcc999cb-xqt94   1/1     Running       0          69s   10.244.2.6   k8s-node2   <none>           <none>
~~~

## Helm安装

### 本地版本：

helm-v3.6.3-linux-amd64.tar.gz

~~~
curl -fsSL -o > get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 --version v3.6.3
~~~

### 创建权限（master 执行）

创建 helm-rbac.yaml，写入如下内容

~~~
[root@k8s-node k8s]# vi helm-rbac.yaml
[root@k8s-node k8s]# cat helm-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1 
kind: ClusterRoleBinding
metadata:
  name: tiller 
roleRef:
  apiGroup: rbac.authorization.k8s.io 
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
[root@k8s-node k8s]# kubectl apply -f helm-rbac.yaml 
serviceaccount/tiller created
clusterrolebinding.rbac.authorization.k8s.io/tiller created
~~~

### 去除污点

~~~
[root@k8s-node k8s]# kubectl get node -o wide
NAME        STATUS   ROLES    AGE   VERSION   INTERNAL-IP       EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION           CONTAINER-RUNTIME
k8s-node    Ready    master   42m   v1.19.3   192.168.121.145   <none>        CentOS Linux 7 (Core)   3.10.0-1160.el7.x86_64   docker://19.3.15
k8s-node1   Ready    <none>   39m   v1.19.3   192.168.121.146   <none>        CentOS Linux 7 (Core)   3.10.0-1160.el7.x86_64   docker://19.3.15
k8s-node2   Ready    <none>   39m   v1.19.3   192.168.121.147   <none>        CentOS Linux 7 (Core)   3.10.0-1160.el7.x86_64   docker://19.3.15
[root@k8s-node k8s]# kubectl describe node k8s-node | grep Taint
Taints:             node-role.kubernetes.io/master:NoSchedule
[root@k8s-node k8s]# kubectl taint nodes k8s-node node-role.kubernetes.io/master:NoSchedule-
node/k8s-node untainted
~~~

